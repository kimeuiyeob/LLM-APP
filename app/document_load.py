from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredWordDocumentLoader,
    CSVLoader
)
from langchain.text_splitter import (
    MarkdownHeaderTextSplitter,
    CharacterTextSplitter,
    RecursiveCharacterTextSplitter
)
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

import streamlit as st
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# í™•ì¥ìë³„ ë¡œë” ë§¤í•‘
loader_map = {
    ".csv": CSVLoader,
    ".pdf": PyPDFLoader,
    ".txt": TextLoader,
    ".docx": UnstructuredWordDocumentLoader,
    ".doc": UnstructuredWordDocumentLoader,
    ".md": TextLoader
}

# í™•ì¥ìë³„ ìŠ¤í”Œë¦¬í„° ë§¤í•‘
splitter_map = {
    ".csv": RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200),
    ".pdf": RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200),
    ".txt": CharacterTextSplitter(chunk_size=1000, chunk_overlap=200),
    ".docx": RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200),
    ".doc": RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200),
    ".md": MarkdownHeaderTextSplitter(headers_to_split_on=["#", "##", "###"])
}

def load_document(file_path: str):
    """
    íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ë¡œë”ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    file_extension = os.path.splitext(file_path)[1].lower()
    loader_class = loader_map.get(file_extension)
    if not loader_class:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í™•ì¥ì: {file_extension}")
    
    # ë¡œë” ì´ˆê¸°í™”
    loader = loader_class(file_path)
    return loader, file_extension


def get_splitter(file_extension: str):
    """
    íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ìŠ¤í”Œë¦¬í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return splitter_map.get(file_extension, RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100))


class EducationPage:
    @staticmethod
    def display():
        st.title("ğŸ“š êµìœ¡")
        st.caption("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ êµìœ¡ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        #st.write("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ êµìœ¡ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")

        # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
        uploaded_file = st.file_uploader("ë¬¸ì„œ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "txt", "csv", "docx", "doc", "md"])
        
        if uploaded_file:
            try:
                # íŒŒì¼ì„ ì„ì‹œ ê²½ë¡œì— ì €ì¥
                temp_path = f"./tmp/{uploaded_file.name}"
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
                st.info("ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
                loader, file_extension = load_document(temp_path)
                splitter = get_splitter(file_extension)
                document_list = loader.load_and_split(text_splitter=splitter)

                # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
                embedding = OpenAIEmbeddings(model='text-embedding-3-large', openai_api_key=api_key)
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                database = Chroma.from_documents(
                    documents=document_list,
                    embedding=embedding,
                    collection_name='chroma-tax',
                    persist_directory="./tmp"
                )

                st.success("ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
